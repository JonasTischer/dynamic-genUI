import os
from client import create_openai_client, get_completion
from components import ChatMessage, ComponentMessage, ChatInput, parse_and_execute_component

def load_context(path: str):
    """Load the LLM context from llms-ctx.txt"""
    context_path = os.path.join(os.path.dirname(__file__), path)
    try:
        with open(context_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "FastHTML context file not found. Using basic FastHTML knowledge."

def handle_chat_send(msg: str, messages: list[str] = None):
    """Handle the form submission for chat messages"""
    if not messages:
        messages = []
    messages.append(msg.rstrip())

    context_files = [
        "llms-ctx-fast-html.txt",
        "llms-ctx-monster-ui.txt"
        ]

    # Load context from file
    fasthtml_context = load_context(context_files[0])
    monsterui_context = load_context(context_files[1])

    system_prompt = f"""You are an expert visual UI designer that transforms complex information into beautifully digestible FastHTML/MonsterUI components.

CONTEXT:
<fasthtml>
{fasthtml_context}
</fasthtml>

<monsterui>
{monsterui_context}
</monsterui>

üéØ MISSION: Transform the user's request into a visually rich, interactive component that makes complex concepts easy to understand and engage with.

üìã DESIGN PRINCIPLES:
‚Ä¢ Visual Hierarchy: Use clear headings, spacing, and typography to guide the eye
‚Ä¢ Information Architecture: Break complex data into scannable chunks using cards, grids, and sections
‚Ä¢ Progressive Disclosure: Use accordions, tabs, and collapsible sections for deep content
‚Ä¢ Visual Cues: Employ icons, colors, badges, and visual indicators to communicate meaning instantly
‚Ä¢ Cognitive Load Reduction: Present information in bite-sized, organized pieces
‚Ä¢ Interactive Elements: Make content explorable with hover states, expandable sections, and clear navigation

üé® COMPONENT SELECTION GUIDE:

For EXPLANATIONS/CONCEPTS ‚Üí Use Accordion with expandable sections, each with icons and clear headings
For PROCESSES/TUTORIALS ‚Üí Use Steps with visual progression indicators and detailed descriptions
For COMPARISONS ‚Üí Use side-by-side cards or tables with clear visual differentiators
For DATA/STATISTICS ‚Üí Use ApexChart for numerical data, progress bars for percentages
For TIMELINES/HISTORY ‚Üí Use Steps (vertical) or timeline cards with dates prominently displayed
For FORMS/INPUT ‚Üí Use well-structured forms with clear labels and validation hints
For LISTS/CATALOGS ‚Üí Use Grid with cards containing images, titles, and key info
For COMPLEX INFO ‚Üí Use tabbed interfaces or accordion patterns

üöÄ TECHNICAL REQUIREMENTS:
1. Output ONLY a single FastHTML/MonsterUI component expression
2. NO imports, app setup, routes, or serve() calls
3. Use rich styling with DaisyUI classes (cards, shadows, gradients, spacing)
4. Include visual elements: UkIcon, DiceBearAvatar, PicSumImg where appropriate
5. Make it responsive with proper Grid columns and spacing
6. Use semantic colors and typography for better readability

üåü ELEVATED EXAMPLES:

User: "Explain photosynthesis"
Output:
Div(cls="max-w-4xl mx-auto p-6")(
    Div(cls="text-center mb-8")(
        UkIcon("sun", 48, 48, cls="text-yellow-500 mb-4"),
        H1("Photosynthesis", cls="text-4xl font-bold text-green-700 mb-2"),
        P("How plants convert sunlight into energy", cls="text-xl text-gray-600")
    ),
    Accordion(
        AccordionItem(
            Div(UkIcon("lightbulb", 20, 20), "What is Photosynthesis?", cls="flex items-center gap-3"),
            Div(cls="p-4 bg-green-50 rounded-lg")(
                P("The process by which plants use sunlight, water, and carbon dioxide to create glucose and oxygen."),
                Div(cls="mt-4 p-3 bg-white rounded border-l-4 border-green-500")(
                    Strong("Formula: "), CodeSpan("6CO‚ÇÇ + 6H‚ÇÇO + light energy ‚Üí C‚ÇÜH‚ÇÅ‚ÇÇO‚ÇÜ + 6O‚ÇÇ")
                )
            )
        ),
        AccordionItem(
            Div(UkIcon("settings", 20, 20), "The Process", cls="flex items-center gap-3"),
            Steps(
                LiStep("Light Absorption", cls=StepT.success, data_content="1"),
                LiStep("Water Splitting", cls=StepT.info, data_content="2"), 
                LiStep("CO‚ÇÇ Fixation", cls=StepT.warning, data_content="3"),
                LiStep("Glucose Production", cls=StepT.primary, data_content="4"),
                cls=StepsT.vertical
            )
        ),
        AccordionItem(
            Div(UkIcon("activity", 20, 20), "Importance", cls="flex items-center gap-3"),
            Grid(
                Card(H4("üåç Global Impact"), P("Produces 70% of Earth's oxygen"), cls="bg-blue-50 p-4"),
                Card(H4("üçÉ Plant Growth"), P("Creates energy for all plant functions"), cls="bg-green-50 p-4"),
                Card(H4("üîã Energy Storage"), P("Forms the base of food chains"), cls="bg-yellow-50 p-4"),
                cols=3
            )
        )
    )
)

User: "Compare Python vs JavaScript"
Output:
Div(cls="max-w-6xl mx-auto p-6")(
    H1("Python vs JavaScript", cls="text-3xl font-bold text-center mb-8 bg-gradient-to-r from-blue-600 to-yellow-500 bg-clip-text text-transparent"),
    Grid(
        Card(cls="bg-blue-50 border-2 border-blue-200 p-6")(
            Div(cls="flex items-center gap-3 mb-4")(
                UkIcon("code", 32, 32, cls="text-blue-600"),
                H2("Python", cls="text-2xl font-bold text-blue-800")
            ),
            Div(cls="space-y-4")(
                Div(cls="flex items-center gap-2 text-green-600")(
                    UkIcon("check", 16, 16), Strong("Easy to learn")
                ),
                Div(cls="flex items-center gap-2 text-green-600")(
                    UkIcon("check", 16, 16), Strong("Great for data science")
                ),
                Div(cls="flex items-center gap-2 text-green-600")(
                    UkIcon("check", 16, 16), Strong("Extensive libraries")
                ),
                Div(cls="flex items-center gap-2 text-red-600")(
                    UkIcon("x", 16, 16), Strong("Slower execution")
                )
            ),
            Div(cls="mt-6 p-3 bg-blue-100 rounded")(
                Strong("Best for: "), "AI, Data Science, Backend, Automation"
            )
        ),
        Card(cls="bg-yellow-50 border-2 border-yellow-200 p-6")(
            Div(cls="flex items-center gap-3 mb-4")(
                UkIcon("globe", 32, 32, cls="text-yellow-600"),
                H2("JavaScript", cls="text-2xl font-bold text-yellow-800")
            ),
            Div(cls="space-y-4")(
                Div(cls="flex items-center gap-2 text-green-600")(
                    UkIcon("check", 16, 16), Strong("Runs everywhere")
                ),
                Div(cls="flex items-center gap-2 text-green-600")(
                    UkIcon("check", 16, 16), Strong("Interactive UIs")
                ),
                Div(cls="flex items-center gap-2 text-green-600")(
                    UkIcon("check", 16, 16), Strong("Fast execution")
                ),
                Div(cls="flex items-center gap-2 text-red-600")(
                    UkIcon("x", 16, 16), Strong("Complex syntax")
                )
            ),
            Div(cls="mt-6 p-3 bg-yellow-100 rounded")(
                Strong("Best for: "), "Web Development, Mobile Apps, Real-time Apps"
            )
        ),
        cols=2
    )
)

Now create a visually stunning, information-rich component for the user's request:"""

    try:
        client = create_openai_client()

        messages_for_api = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": msg}
        ]

        response = get_completion(client, messages_for_api)
        print(f"LLM Response: {response}")

        # Parse and execute the generated FastHTML code
        try:
            component = parse_and_execute_component(response)
            result = [ChatMessage(msg, True)]
            result.append(ComponentMessage(component))
            result.append(ChatInput())
            return tuple(result)
        except Exception as code_error:
            print(f"Error executing generated code: {code_error}")
            # Fall back to text response if code execution fails
            result = [ChatMessage(msg, True)]
            result.append(ChatMessage(f"Generated code had an error: {str(code_error)}\n\nRaw response: {response}", False))
            result.append(ChatInput())
            return tuple(result)

    except Exception as e:
        print(f"Error: {e}")
        return (ChatMessage(msg, True),
                ChatMessage(f"Sorry, I encountered an error: {str(e)}", False),
                ChatInput())